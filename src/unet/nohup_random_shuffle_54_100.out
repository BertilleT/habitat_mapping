----------------------- UNet -----------------------
Patch size: 256
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.6, 0.2, 0.2]
Stratified: random
Batch size: 16
Train: 6397 images, Val: 2133 images, Test: 2133 images
Train: 59.99%, Val: 20.00%, Test: 20.00%
Shape of images and masks:
Image shape: torch.Size([16, 4, 256, 256])
Creating model...
Model settings:
Encoder name: efficientnet-b7
Pretrained: None
Classes: 6
Creating optimizer...
Training settings:
Learning rate: 0.0001
Criterion: Dice
Optimizer: Adam
Training...
Epoch 1/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 1/100: train loss 0.6648, val loss 0.8607
Epoch 1/100: train mIoU 0.2365, val mIoU 0.0381
Time: 0:13:16.665864
Epoch 2/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 2/100: train loss 0.5665, val loss 0.5192
Epoch 2/100: train mIoU 0.3003, val mIoU 0.3638
Time: 0:13:13.911003
Epoch 3/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 3/100: train loss 0.5397, val loss 0.4807
Epoch 3/100: train mIoU 0.3288, val mIoU 0.3907
Time: 0:13:12.772597
Epoch 4/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 4/100: train loss 0.5029, val loss 0.4654
Epoch 4/100: train mIoU 0.3482, val mIoU 0.4134
Time: 0:13:14.147264
Epoch 5/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 5/100: train loss 0.4921, val loss 0.5322
Epoch 5/100: train mIoU 0.3596, val mIoU 0.3401
Time: 0:13:12.690492
Epoch 6/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 6/100: train loss 0.4845, val loss 0.4643
Epoch 6/100: train mIoU 0.3707, val mIoU 0.4112
Time: 0:13:12.546838
Epoch 7/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 7/100: train loss 0.4681, val loss 0.4376
Epoch 7/100: train mIoU 0.3827, val mIoU 0.4323
