----------------------- UNet -----------------------
Patch size: 256
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.6, 0.2, 0.2]
Stratified: random
Batch size: 16
Train: 6397 images, Val: 2133 images, Test: 2133 images
Train: 59.99%, Val: 20.00%, Test: 20.00%
/home/bertille/miniconda3/envs/ecomed_venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/bertille/miniconda3/envs/ecomed_venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Creating model...
Model settings:
Encoder name: efficientnet-b7
Pretrained: None
Classes: 6
Creating optimizer...
Training settings:
Learning rate: 0.0001
Criterion: Dice
Optimizer: Adam
Training...
Epoch 1/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 1/200: train loss 0.6973, val loss 0.8031
Epoch 1/200: train mIoU 0.2146, val mIoU 0.0694
Epoch 2/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 2/200: train loss 0.6014, val loss 0.5698
Epoch 2/200: train mIoU 0.2755, val mIoU 0.3066
Epoch 3/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 3/200: train loss 0.5627, val loss 0.5308
Epoch 3/200: train mIoU 0.2992, val mIoU 0.3433
Epoch 4/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 4/200: train loss 0.5353, val loss 0.5431
Epoch 4/200: train mIoU 0.3185, val mIoU 0.3286
Epoch 5/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 5/200: train loss 0.5187, val loss 0.5005
Epoch 5/200: train mIoU 0.3312, val mIoU 0.3672
Epoch 6/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 6/200: train loss 0.5115, val loss 0.4937
Epoch 6/200: train mIoU 0.3387, val mIoU 0.3751
Epoch 7/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 7/200: train loss 0.4932, val loss 0.5112
Epoch 7/200: train mIoU 0.3508, val mIoU 0.3656
Epoch 8/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 8/200: train loss 0.4880, val loss 0.4868
Epoch 8/200: train mIoU 0.3621, val mIoU 0.3837
Epoch 9/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 9/200: train loss 0.4761, val loss 0.4696
Epoch 9/200: train mIoU 0.3748, val mIoU 0.4062
Epoch 10/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 10/200: train loss 0.4686, val loss 0.5004
Epoch 10/200: train mIoU 0.3757, val mIoU 0.3771
Epoch 11/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 11/200: train loss 0.4701, val loss 0.4723
Epoch 11/200: train mIoU 0.3805, val mIoU 0.3989
Epoch 12/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 12/200: train loss 0.4631, val loss 0.4683
Epoch 12/200: train mIoU 0.3837, val mIoU 0.4031
Epoch 13/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 13/200: train loss 0.4592, val loss 0.4525
Epoch 13/200: train mIoU 0.3869, val mIoU 0.4313
Epoch 14/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 14/200: train loss 0.4548, val loss 0.4641
Epoch 14/200: train mIoU 0.3951, val mIoU 0.4132
Epoch 15/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 15/200: train loss 0.4440, val loss 0.4437
Epoch 15/200: train mIoU 0.4051, val mIoU 0.4375
Epoch 16/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 16/200: train loss 0.4460, val loss 0.4429
Epoch 16/200: train mIoU 0.3995, val mIoU 0.4297
Epoch 17/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 17/200: train loss 0.4398, val loss 0.4506
Epoch 17/200: train mIoU 0.4058, val mIoU 0.4272
Epoch 18/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 18/200: train loss 0.4361, val loss 0.4286
Epoch 18/200: train mIoU 0.4171, val mIoU 0.4525
Epoch 19/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 19/200: train loss 0.4275, val loss 0.4400
Epoch 19/200: train mIoU 0.4197, val mIoU 0.4380
Epoch 20/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 20/200: train loss 0.4260, val loss 0.4682
Epoch 20/200: train mIoU 0.4224, val mIoU 0.4134
Epoch 21/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 21/200: train loss 0.4276, val loss 0.4365
Epoch 21/200: train mIoU 0.4209, val mIoU 0.4516
Epoch 22/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 22/200: train loss 0.4121, val loss 0.4423
Epoch 22/200: train mIoU 0.4364, val mIoU 0.4289
Epoch 23/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 23/200: train loss 0.4207, val loss 0.4269
Epoch 23/200: train mIoU 0.4315, val mIoU 0.4564
Epoch 24/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 24/200: train loss 0.4042, val loss 0.4288
Epoch 24/200: train mIoU 0.4502, val mIoU 0.4495
Epoch 25/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 25/200: train loss 0.4048, val loss 0.4302
Epoch 25/200: train mIoU 0.4424, val mIoU 0.4442
Epoch 26/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 26/200: train loss 0.4052, val loss 0.4091
Epoch 26/200: train mIoU 0.4461, val mIoU 0.4676
Epoch 27/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 27/200: train loss 0.3989, val loss 0.4696
Epoch 27/200: train mIoU 0.4539, val mIoU 0.4061
Epoch 28/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 28/200: train loss 0.4016, val loss 0.4216
Epoch 28/200: train mIoU 0.4549, val mIoU 0.4601
Epoch 29/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 29/200: train loss 0.3967, val loss 0.4205
Epoch 29/200: train mIoU 0.4614, val mIoU 0.4570
Epoch 30/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 30/200: train loss 0.4012, val loss 0.4284
Epoch 30/200: train mIoU 0.4516, val mIoU 0.4388
Epoch 31/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 31/200: train loss 0.3959, val loss 0.4280
Epoch 31/200: train mIoU 0.4666, val mIoU 0.4422
Epoch 32/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 32/200: train loss 0.3836, val loss 0.4208
Epoch 32/200: train mIoU 0.4709, val mIoU 0.4599
Epoch 33/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 33/200: train loss 0.3775, val loss 0.4366
Epoch 33/200: train mIoU 0.4806, val mIoU 0.4494
Epoch 34/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 34/200: train loss 0.3798, val loss 0.3996
Epoch 34/200: train mIoU 0.4762, val mIoU 0.4821
Epoch 35/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 35/200: train loss 0.3780, val loss 0.4214
Epoch 35/200: train mIoU 0.4769, val mIoU 0.4681
Epoch 36/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 36/200: train loss 0.3780, val loss 0.5006
Epoch 36/200: train mIoU 0.4792, val mIoU 0.3690
Epoch 37/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 37/200: train loss 0.3719, val loss 0.4130
Epoch 37/200: train mIoU 0.4904, val mIoU 0.4656
Epoch 38/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 38/200: train loss 0.3715, val loss 0.4327
Epoch 38/200: train mIoU 0.4893, val mIoU 0.4431
Epoch 39/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 39/200: train loss 0.3687, val loss 0.4156
Epoch 39/200: train mIoU 0.4949, val mIoU 0.4620
Epoch 40/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 40/200: train loss 0.3572, val loss 0.4199
Epoch 40/200: train mIoU 0.5077, val mIoU 0.4509
Epoch 41/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 41/200: train loss 0.3599, val loss 0.3980
Epoch 41/200: train mIoU 0.5068, val mIoU 0.4846
Epoch 42/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 42/200: train loss 0.3639, val loss 0.4142
Epoch 42/200: train mIoU 0.5049, val mIoU 0.4601
Epoch 43/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 43/200: train loss 0.3572, val loss 0.3785
Epoch 43/200: train mIoU 0.5115, val mIoU 0.5013
Epoch 44/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 44/200: train loss 0.3513, val loss 0.4378
Epoch 44/200: train mIoU 0.5210, val mIoU 0.4495
Epoch 45/200
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 45/200: train loss 0.3498, val loss 0.4024
Epoch 45/200: train mIoU 0.5160, val mIoU 0.4707
