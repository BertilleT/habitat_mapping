----------------------- UNet -----------------------
Patch size: 64
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.68, 0.2]
Stratified: zone
Year: all
Patches: all
Batch size: 4096
Normalisation: channel_by_channel
Data augmentation
The seed to shuffle the data is  1
The data are from  all  year
Nbumber of unique zones: 108
Train, val and test zones saved in csv file at: ../../results/resnet18_64_l1/stratified_shuffling_by_zone/seed1/img_ids_by_set.csv
Image: min: 0.0, max: 1.0
Mask unique values: [0. 1.]
Train: 102118 images, Val: 36030 images, Test: 32320 images
Train: 59.90%, Val: 21.14%, Test: 18.96%
Creating model...
Model settings:
Pretrained: True
Classes: 7
The model is Resnet18
Pretrained weights loaded
Using BCEWithDigits criterion
Creating optimizer...
Training settings:
Learning rate: 0.001
Criterion: BCEWithDigits
Optimizer: Adam
Training...
Epoch 1/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 1/80: train loss 0.4276, val loss 0.4897
Epoch 1/80: train mF1 0.3940, val mF1 0.2980
Time: 0:08:35.096858
Epoch 2/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 2/80: train loss 0.3406, val loss 0.4313
Epoch 2/80: train mF1 0.5066, val mF1 0.3293
Time: 0:08:40.597209
Epoch 3/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 3/80: train loss 0.3202, val loss 0.4679
Epoch 3/80: train mF1 0.5503, val mF1 0.3177
Time: 0:08:48.845343
Epoch 4/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 4/80: train loss 0.3070, val loss 0.4334
Epoch 4/80: train mF1 0.5761, val mF1 0.3495
Time: 0:08:50.327584
Epoch 5/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 5/80: train loss 0.2984, val loss 0.4330
Epoch 5/80: train mF1 0.5927, val mF1 0.3497
Time: 0:08:58.958965
Epoch 6/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 6/80: train loss 0.2915, val loss 0.4276
Epoch 6/80: train mF1 0.6061, val mF1 0.3593
Time: 0:09:21.763748
Epoch 7/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 7/80: train loss 0.2856, val loss 0.4645
Epoch 7/80: train mF1 0.6152, val mF1 0.3298
Time: 0:09:19.802508
Epoch 8/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 8/80: train loss 0.2801, val loss 0.4494
Epoch 8/80: train mF1 0.6249, val mF1 0.3838
Time: 0:09:19.799518
Epoch 9/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 9/80: train loss 0.2761, val loss 0.4784
Epoch 9/80: train mF1 0.6335, val mF1 0.3333
Time: 0:09:18.675475
Epoch 10/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 10/80: train loss 0.2718, val loss 0.4262
Epoch 10/80: train mF1 0.6391, val mF1 0.3717
Time: 0:09:16.668363
Epoch 11/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 11/80: train loss 0.2679, val loss 0.4683
Epoch 11/80: train mF1 0.6451, val mF1 0.3555
Time: 0:09:20.455901
Epoch 12/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 12/80: train loss 0.2636, val loss 0.4878
Epoch 12/80: train mF1 0.6545, val mF1 0.3259
Time: 0:09:22.048084
Epoch 13/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 13/80: train loss 0.2613, val loss 0.5146
Epoch 13/80: train mF1 0.6583, val mF1 0.3662
Time: 0:09:26.617439
Epoch 14/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 14/80: train loss 0.2579, val loss 0.4548
Epoch 14/80: train mF1 0.6615, val mF1 0.3498
Time: 0:09:20.997935
Epoch 15/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 15/80: train loss 0.2540, val loss 0.4669
Epoch 15/80: train mF1 0.6691, val mF1 0.3651
Time: 0:09:19.858717
Epoch 16/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 16/80: train loss 0.2510, val loss 0.5083
Epoch 16/80: train mF1 0.6733, val mF1 0.3377
Time: 0:09:22.774728
Epoch 17/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 17/80: train loss 0.2488, val loss 0.4906
Epoch 17/80: train mF1 0.6771, val mF1 0.3433
Time: 0:09:21.050768
Epoch 18/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 18/80: train loss 0.2460, val loss 0.5121
Epoch 18/80: train mF1 0.6824, val mF1 0.3219
Time: 0:09:20.166634
Epoch 19/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 19/80: train loss 0.2440, val loss 0.5116
Epoch 19/80: train mF1 0.6852, val mF1 0.3973
Time: 0:09:23.510107
Epoch 20/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 20/80: train loss 0.2415, val loss 0.5047
Epoch 20/80: train mF1 0.6912, val mF1 0.3353
Time: 0:09:22.592628
Epoch 21/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 21/80: train loss 0.2374, val loss 0.5104
Epoch 21/80: train mF1 0.6971, val mF1 0.3468
Time: 0:09:27.100603
Epoch 22/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 22/80: train loss 0.2359, val loss 0.5112
Epoch 22/80: train mF1 0.6979, val mF1 0.3283
Time: 0:09:26.855507
Epoch 23/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 23/80: train loss 0.2325, val loss 0.4744
Epoch 23/80: train mF1 0.7038, val mF1 0.3715
Time: 0:09:23.488538
Epoch 24/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 24/80: train loss 0.2301, val loss 0.4977
Epoch 24/80: train mF1 0.7087, val mF1 0.3663
Time: 0:09:22.967775
Epoch 25/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 25/80: train loss 0.2272, val loss 0.5287
Epoch 25/80: train mF1 0.7126, val mF1 0.3566
Time: 0:09:17.496178
Epoch 26/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 26/80: train loss 0.2257, val loss 0.5405
Epoch 26/80: train mF1 0.7137, val mF1 0.3309
Time: 0:09:18.257331
Epoch 27/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 27/80: train loss 0.2232, val loss 0.5179
Epoch 27/80: train mF1 0.7179, val mF1 0.3380
Time: 0:09:25.018219
Epoch 28/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 28/80: train loss 0.2207, val loss 0.5365
Epoch 28/80: train mF1 0.7225, val mF1 0.3418
Time: 0:09:22.401006
Epoch 29/80
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 29/80: train loss 0.2194, val loss 0.5074
Epoch 29/80: train mF1 0.7249, val mF1 0.3666
