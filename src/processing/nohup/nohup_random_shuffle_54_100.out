----------------------- UNet -----------------------
Patch size: 256
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.6, 0.2, 0.2]
Stratified: random
Batch size: 16
Train: 6397 images, Val: 2133 images, Test: 2133 images
Train: 59.99%, Val: 20.00%, Test: 20.00%
Shape of images and masks:
Image shape: torch.Size([16, 4, 256, 256])
Creating model...
Model settings:
Encoder name: efficientnet-b7
Pretrained: None
Classes: 6
Creating optimizer...
Training settings:
Learning rate: 0.0001
Criterion: Dice
Optimizer: Adam
Training...
Epoch 1/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 1/100: train loss 0.6648, val loss 0.8607
Epoch 1/100: train mIoU 0.2365, val mIoU 0.0381
Time: 0:13:16.665864
Epoch 2/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 2/100: train loss 0.5665, val loss 0.5192
Epoch 2/100: train mIoU 0.3003, val mIoU 0.3638
Time: 0:13:13.911003
Epoch 3/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 3/100: train loss 0.5397, val loss 0.4807
Epoch 3/100: train mIoU 0.3288, val mIoU 0.3907
Time: 0:13:12.772597
Epoch 4/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 4/100: train loss 0.5029, val loss 0.4654
Epoch 4/100: train mIoU 0.3482, val mIoU 0.4134
Time: 0:13:14.147264
Epoch 5/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 5/100: train loss 0.4921, val loss 0.5322
Epoch 5/100: train mIoU 0.3596, val mIoU 0.3401
Time: 0:13:12.690492
Epoch 6/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 6/100: train loss 0.4845, val loss 0.4643
Epoch 6/100: train mIoU 0.3707, val mIoU 0.4112
Time: 0:13:12.546838
Epoch 7/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 7/100: train loss 0.4681, val loss 0.4376
Epoch 7/100: train mIoU 0.3827, val mIoU 0.4323
Time: 0:13:12.269506
Epoch 8/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 8/100: train loss 0.4542, val loss 0.4382
Epoch 8/100: train mIoU 0.3939, val mIoU 0.4331
Time: 0:13:16.514289
Epoch 9/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 9/100: train loss 0.4503, val loss 0.4489
Epoch 9/100: train mIoU 0.3978, val mIoU 0.4285
Time: 0:13:14.471926
Epoch 10/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 10/100: train loss 0.4512, val loss 0.4227
Epoch 10/100: train mIoU 0.4019, val mIoU 0.4633
Time: 0:13:15.361616
Epoch 11/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 11/100: train loss 0.4281, val loss 0.4091
Epoch 11/100: train mIoU 0.4203, val mIoU 0.4692
Time: 0:13:15.037139
Epoch 12/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 12/100: train loss 0.4378, val loss 0.4229
Epoch 12/100: train mIoU 0.4204, val mIoU 0.4547
Time: 0:13:13.471506
Epoch 13/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 13/100: train loss 0.4328, val loss 0.4224
Epoch 13/100: train mIoU 0.4193, val mIoU 0.4506
Time: 0:13:12.197690
Epoch 14/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 14/100: train loss 0.4242, val loss 0.4236
Epoch 14/100: train mIoU 0.4283, val mIoU 0.4547
Time: 0:13:12.993350
Epoch 15/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 15/100: train loss 0.4170, val loss 0.4296
Epoch 15/100: train mIoU 0.4293, val mIoU 0.4463
Time: 0:13:13.070157
Epoch 16/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 16/100: train loss 0.4134, val loss 0.4143
Epoch 16/100: train mIoU 0.4391, val mIoU 0.4677
Time: 0:13:12.026382
Epoch 17/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 17/100: train loss 0.4080, val loss 0.4191
Epoch 17/100: train mIoU 0.4479, val mIoU 0.4535
Time: 0:13:12.333848
Epoch 18/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 18/100: train loss 0.4086, val loss 0.4043
Epoch 18/100: train mIoU 0.4467, val mIoU 0.4731
Time: 0:13:13.708153
Epoch 19/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 19/100: train loss 0.4056, val loss 0.3936
Epoch 19/100: train mIoU 0.4501, val mIoU 0.4888
Time: 0:13:14.606945
Epoch 20/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 20/100: train loss 0.4081, val loss 0.4193
Epoch 20/100: train mIoU 0.4525, val mIoU 0.4568
Time: 0:13:12.280274
Epoch 21/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 21/100: train loss 0.4037, val loss 0.4200
Epoch 21/100: train mIoU 0.4598, val mIoU 0.4570
Time: 0:13:11.885452
Epoch 22/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 22/100: train loss 0.3992, val loss 0.4050
Epoch 22/100: train mIoU 0.4584, val mIoU 0.4738
Time: 0:13:13.053643
Epoch 23/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 23/100: train loss 0.3962, val loss 0.3974
Epoch 23/100: train mIoU 0.4601, val mIoU 0.4794
Time: 0:13:13.202332
Epoch 24/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 24/100: train loss 0.3909, val loss 0.3742
Epoch 24/100: train mIoU 0.4638, val mIoU 0.5119
Time: 0:13:14.640287
Epoch 25/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 25/100: train loss 0.3972, val loss 0.3901
Epoch 25/100: train mIoU 0.4679, val mIoU 0.4917
Time: 0:13:13.798288
Epoch 26/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 26/100: train loss 0.3870, val loss 0.3958
Epoch 26/100: train mIoU 0.4764, val mIoU 0.4924
Time: 0:13:12.404580
Epoch 27/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 27/100: train loss 0.3820, val loss 0.3901
Epoch 27/100: train mIoU 0.4779, val mIoU 0.4961
Time: 0:13:13.012290
Epoch 28/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 28/100: train loss 0.3871, val loss 0.3873
Epoch 28/100: train mIoU 0.4795, val mIoU 0.4976
Time: 0:13:11.993815
Epoch 29/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 29/100: train loss 0.3787, val loss 0.4083
Epoch 29/100: train mIoU 0.4867, val mIoU 0.4678
Time: 0:13:12.646150
Epoch 30/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 30/100: train loss 0.3782, val loss 0.4014
Epoch 30/100: train mIoU 0.4862, val mIoU 0.4706
Time: 0:13:12.622825
Epoch 31/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 31/100: train loss 0.3792, val loss 0.4154
Epoch 31/100: train mIoU 0.4826, val mIoU 0.4661
Time: 0:13:12.679026
Epoch 32/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 32/100: train loss 0.3718, val loss 0.4116
Epoch 32/100: train mIoU 0.4914, val mIoU 0.4800
Time: 0:13:12.302097
Epoch 33/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 33/100: train loss 0.3841, val loss 0.4400
Epoch 33/100: train mIoU 0.4798, val mIoU 0.4361
Time: 0:13:11.994954
Epoch 34/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 34/100: train loss 0.3754, val loss 0.3948
Epoch 34/100: train mIoU 0.4933, val mIoU 0.4913
Time: 0:13:11.996539
Epoch 35/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 35/100: train loss 0.3742, val loss 0.3953
Epoch 35/100: train mIoU 0.4993, val mIoU 0.4886
Time: 0:13:12.041602
Epoch 36/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 36/100: train loss 0.3777, val loss 0.4097
Epoch 36/100: train mIoU 0.4853, val mIoU 0.4691
Time: 0:13:12.874774
Epoch 37/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 37/100: train loss 0.3622, val loss 0.3892
Epoch 37/100: train mIoU 0.5046, val mIoU 0.4994
Time: 0:13:12.060231
Epoch 38/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 38/100: train loss 0.3561, val loss 0.3690
Epoch 38/100: train mIoU 0.5134, val mIoU 0.5191
Time: 0:13:12.429189
Epoch 39/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 39/100: train loss 0.3560, val loss 0.3859
Epoch 39/100: train mIoU 0.5142, val mIoU 0.4978
Time: 0:13:12.254574
Epoch 40/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 40/100: train loss 0.3547, val loss 0.3716
Epoch 40/100: train mIoU 0.5117, val mIoU 0.5142
Time: 0:13:12.279198
Epoch 41/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 41/100: train loss 0.3509, val loss 0.3778
Epoch 41/100: train mIoU 0.5170, val mIoU 0.5059
Time: 0:13:12.550442
Epoch 42/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 42/100: train loss 0.3581, val loss 0.3718
Epoch 42/100: train mIoU 0.5092, val mIoU 0.5163
Time: 0:13:12.601896
Epoch 43/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 43/100: train loss 0.3483, val loss 0.4436
Epoch 43/100: train mIoU 0.5226, val mIoU 0.4266
Time: 0:13:12.772444
Epoch 44/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 44/100: train loss 0.3521, val loss 0.3674
Epoch 44/100: train mIoU 0.5167, val mIoU 0.5211
Time: 0:13:12.091849
Epoch 45/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 45/100: train loss 0.3452, val loss 0.3852
Epoch 45/100: train mIoU 0.5281, val mIoU 0.5000
Time: 0:13:11.428570
Epoch 46/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 46/100: train loss 0.3461, val loss 0.3843
Epoch 46/100: train mIoU 0.5228, val mIoU 0.4938
Time: 0:13:11.105366
Epoch 47/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 47/100: train loss 0.3404, val loss 0.3660
Epoch 47/100: train mIoU 0.5358, val mIoU 0.5305
Time: 0:13:12.027816
Epoch 48/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 48/100: train loss 0.3355, val loss 0.3991
Epoch 48/100: train mIoU 0.5415, val mIoU 0.4894
Time: 0:13:12.109620
Epoch 49/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 49/100: train loss 0.3517, val loss 0.3660
Epoch 49/100: train mIoU 0.5223, val mIoU 0.5238
Time: 0:13:12.916472
Epoch 50/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 50/100: train loss 0.3410, val loss 0.3747
Epoch 50/100: train mIoU 0.5322, val mIoU 0.5221
Time: 0:13:12.698771
Epoch 51/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 51/100: train loss 0.3331, val loss 0.3480
Epoch 51/100: train mIoU 0.5484, val mIoU 0.5461
Time: 0:13:15.203539
Epoch 52/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 52/100: train loss 0.3370, val loss 0.3781
Epoch 52/100: train mIoU 0.5412, val mIoU 0.5071
Time: 0:13:14.187147
Epoch 53/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 53/100: train loss 0.3296, val loss 0.3750
Epoch 53/100: train mIoU 0.5480, val mIoU 0.5188
Time: 0:13:13.413188
Epoch 54/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 54/100: train loss 0.3455, val loss 0.3725
Epoch 54/100: train mIoU 0.5365, val mIoU 0.5155
Time: 0:13:13.770239
Epoch 55/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 55/100: train loss 0.3427, val loss 0.3910
Epoch 55/100: train mIoU 0.5390, val mIoU 0.4930
Time: 0:13:14.557349
Epoch 56/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 56/100: train loss 0.3385, val loss 0.3606
Epoch 56/100: train mIoU 0.5433, val mIoU 0.5217
Time: 0:13:12.989017
Epoch 57/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 57/100: train loss 0.3239, val loss 0.3667
Epoch 57/100: train mIoU 0.5590, val mIoU 0.5204
Time: 0:13:14.478091
Epoch 58/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 58/100: train loss 0.3194, val loss 0.3742
Epoch 58/100: train mIoU 0.5620, val mIoU 0.5055
Time: 0:13:13.538858
Epoch 59/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 59/100: train loss 0.3147, val loss 0.3514
Epoch 59/100: train mIoU 0.5635, val mIoU 0.5405
Time: 0:13:13.538846
Epoch 60/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 60/100: train loss 0.3181, val loss 0.3438
Epoch 60/100: train mIoU 0.5707, val mIoU 0.5547
Time: 0:13:14.143587
Epoch 61/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 61/100: train loss 0.3282, val loss 0.3732
Epoch 61/100: train mIoU 0.5579, val mIoU 0.5242
Time: 0:13:12.851424
Epoch 62/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 62/100: train loss 0.3167, val loss 0.3483
Epoch 62/100: train mIoU 0.5667, val mIoU 0.5477
Time: 0:13:13.059677
Epoch 63/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 63/100: train loss 0.3111, val loss 0.3610
Epoch 63/100: train mIoU 0.5737, val mIoU 0.5263
Time: 0:13:13.332749
Epoch 64/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 64/100: train loss 0.3165, val loss 0.3477
Epoch 64/100: train mIoU 0.5670, val mIoU 0.5463
Time: 0:13:12.976378
Epoch 65/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 65/100: train loss 0.3073, val loss 0.3643
Epoch 65/100: train mIoU 0.5795, val mIoU 0.5249
Time: 0:13:13.825590
Epoch 66/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 66/100: train loss 0.3066, val loss 0.3590
Epoch 66/100: train mIoU 0.5824, val mIoU 0.5280
Time: 0:13:14.279403
Epoch 67/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 67/100: train loss 0.3129, val loss 0.3483
Epoch 67/100: train mIoU 0.5750, val mIoU 0.5404
Time: 0:13:13.314749
Epoch 68/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 68/100: train loss 0.3062, val loss 0.3778
Epoch 68/100: train mIoU 0.5770, val mIoU 0.5150
Time: 0:13:13.055794
Epoch 69/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 69/100: train loss 0.3149, val loss 0.4056
Epoch 69/100: train mIoU 0.5644, val mIoU 0.4812
Time: 0:13:13.110751
Epoch 70/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 70/100: train loss 0.3089, val loss 0.3559
Epoch 70/100: train mIoU 0.5778, val mIoU 0.5479
Time: 0:13:13.506360
Epoch 71/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 71/100: train loss 0.3036, val loss 0.3921
Epoch 71/100: train mIoU 0.5827, val mIoU 0.5018
Time: 0:13:13.043299
Epoch 72/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 72/100: train loss 0.3082, val loss 0.3476
Epoch 72/100: train mIoU 0.5776, val mIoU 0.5414
Time: 0:13:13.637963
Epoch 73/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 73/100: train loss 0.3008, val loss 0.3568
Epoch 73/100: train mIoU 0.5804, val mIoU 0.5429
Time: 0:13:14.036583
Epoch 74/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 74/100: train loss 0.2902, val loss 0.3628
Epoch 74/100: train mIoU 0.6013, val mIoU 0.5174
/home/bertille/.local/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/bertille/.local/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Time: 0:13:15.610218
Epoch 75/100
Training
Batch: 0  over  400
Batch: 50  over  400
Batch: 100  over  400
Batch: 150  over  400
Batch: 200  over  400
Batch: 250  over  400
Batch: 300  over  400
Batch: 350  over  400
Validation
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Epoch 75/100: train loss 0.2937, val loss 0.3464
Epoch 75/100: train mIoU 0.6007, val mIoU 0.5464
Early stopping at epoch 75
Testing
Batch: 0  over  134
Batch: 50  over  134
Batch: 100  over  134
Test IoU by class: {0: 0.42348804125995526, 1: 0.5585192231250535, 2: 0.6987911623536294, 3: 0.630009902568735, 4: 0.5283414892072255, 5: 0.5087647487820091}
Test F1 by class: {0: 0.5950004903239206, 1: 0.7167306181891587, 2: 0.8226922506301163, 3: 0.7730135891516996, 4: 0.691391934247999, 5: 0.6744122954790972}
Test mIoU: 0.5579857612161013
Test mF1: 0.7122068630036652
