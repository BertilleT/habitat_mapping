INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations
----------------------- UNet -----------------------
Patch size: 64
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.6, 0.2]
Stratified: random
Year: all
Patches: all
Batch size: 4096
Normalisation: channel_by_channel
No data augmentation
The seed to shuffle the data is  1
The data are from  all  year
Image: min: 0.0, max: 1.0
Mask unique values: [0. 1.]
Train: 99564 images, Val: 33188 images, Test: 37716 images
Train: 58.41%, Val: 19.47%, Test: 22.12%
Creating model...
Model settings:
Pretrained: True
Classes: 7
The model is Resnet18
Pretrained weights loaded
Using BCEWithDigits criterion
Creating optimizer...
Training settings:
Learning rate: 0.001
Criterion: BCEWithDigits
Optimizer: Adam
Training...
Epoch 1/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 1/60: train loss 0.3724, val loss 0.5537
Epoch 1/60: train mF1 0.4681, val mF1 0.2959
Time: 0:06:51.556003
Epoch 2/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 2/60: train loss 0.2725, val loss 0.3105
Epoch 2/60: train mF1 0.6233, val mF1 0.5945
Time: 0:06:56.096645
Epoch 3/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 3/60: train loss 0.2285, val loss 0.3096
Epoch 3/60: train mF1 0.6937, val mF1 0.5969
Time: 0:06:55.790639
Epoch 4/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 4/60: train loss 0.1897, val loss 0.3070
Epoch 4/60: train mF1 0.7537, val mF1 0.6269
Time: 0:06:57.002198
Epoch 5/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 5/60: train loss 0.1481, val loss 0.3365
Epoch 5/60: train mF1 0.8156, val mF1 0.6395
Time: 0:06:56.662592
Epoch 6/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 6/60: train loss 0.1090, val loss 0.3804
Epoch 6/60: train mF1 0.8706, val mF1 0.6376
Time: 0:06:53.230857
Epoch 7/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 7/60: train loss 0.0781, val loss 0.4275
Epoch 7/60: train mF1 0.9125, val mF1 0.6253
Time: 0:06:54.115892
Epoch 8/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 8/60: train loss 0.0560, val loss 0.4279
Epoch 8/60: train mF1 0.9411, val mF1 0.6392
Time: 0:06:53.342532
Epoch 9/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 9/60: train loss 0.0392, val loss 0.4858
Epoch 9/60: train mF1 0.9614, val mF1 0.6214
Time: 0:06:53.737426
Epoch 10/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 10/60: train loss 0.0279, val loss 0.4930
Epoch 10/60: train mF1 0.9735, val mF1 0.6376
Time: 0:06:52.627521
Epoch 11/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 11/60: train loss 0.0198, val loss 0.5000
Epoch 11/60: train mF1 0.9824, val mF1 0.6590
Time: 0:06:56.751857
Epoch 12/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 12/60: train loss 0.0144, val loss 0.5204
Epoch 12/60: train mF1 0.9881, val mF1 0.6538
Time: 0:07:02.139810
Epoch 13/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 13/60: train loss 0.0100, val loss 0.5248
Epoch 13/60: train mF1 0.9923, val mF1 0.6635
Time: 0:07:00.902603
Epoch 14/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 14/60: train loss 0.0071, val loss 0.5560
Epoch 14/60: train mF1 0.9952, val mF1 0.6580
Time: 0:07:06.349002
Epoch 15/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 15/60: train loss 0.0052, val loss 0.5475
Epoch 15/60: train mF1 0.9968, val mF1 0.6672
Time: 0:07:01.779684
Epoch 16/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 16/60: train loss 0.0038, val loss 0.5666
Epoch 16/60: train mF1 0.9977, val mF1 0.6715
Time: 0:06:56.478744
Epoch 17/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 17/60: train loss 0.0025, val loss 0.5708
Epoch 17/60: train mF1 0.9987, val mF1 0.6742
Time: 0:06:57.220030
Epoch 18/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 18/60: train loss 0.0017, val loss 0.5734
Epoch 18/60: train mF1 0.9992, val mF1 0.6742
Time: 0:06:57.790617
Epoch 19/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 19/60: train loss 0.0010, val loss 0.5809
Epoch 19/60: train mF1 0.9996, val mF1 0.6730
Time: 0:06:57.314062
Epoch 20/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 20/60: train loss 0.0009, val loss 0.5824
Epoch 20/60: train mF1 0.9996, val mF1 0.6779
Time: 0:06:56.895656
Epoch 21/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 21/60: train loss 0.0008, val loss 0.5833
Epoch 21/60: train mF1 0.9995, val mF1 0.6773
Time: 0:06:59.660815
Epoch 22/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 22/60: train loss 0.0012, val loss 0.6032
Epoch 22/60: train mF1 0.9994, val mF1 0.6710
Time: 0:06:56.632258
Epoch 23/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 23/60: train loss 0.0007, val loss 0.6104
Epoch 23/60: train mF1 0.9998, val mF1 0.6737
Time: 0:06:55.555817
Epoch 24/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 24/60: train loss 0.0004, val loss 0.5931
Epoch 24/60: train mF1 0.9999, val mF1 0.6767
Time: 0:06:54.445519
Epoch 25/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 25/60: train loss 0.0002, val loss 0.5979
Epoch 25/60: train mF1 1.0000, val mF1 0.6779
Time: 0:06:53.181484
Epoch 26/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 26/60: train loss 0.0002, val loss 0.5994
Epoch 26/60: train mF1 1.0000, val mF1 0.6786
Time: 0:06:54.268231
Epoch 27/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 27/60: train loss 0.0001, val loss 0.6002
Epoch 27/60: train mF1 1.0000, val mF1 0.6791
Time: 0:06:57.291908
Epoch 28/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 28/60: train loss 0.0001, val loss 0.6026
Epoch 28/60: train mF1 1.0000, val mF1 0.6801
Time: 0:06:54.890797
Epoch 29/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 29/60: train loss 0.0001, val loss 0.6052
Epoch 29/60: train mF1 1.0000, val mF1 0.6786
Time: 0:06:54.488721
Epoch 30/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 30/60: train loss 0.0001, val loss 0.6061
Epoch 30/60: train mF1 1.0000, val mF1 0.6792
Time: 0:06:54.954030
Epoch 31/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 31/60: train loss 0.0001, val loss 0.6088
Epoch 31/60: train mF1 1.0000, val mF1 0.6789
Time: 0:07:04.981978
Epoch 32/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 32/60: train loss 0.0001, val loss 0.6106
Epoch 32/60: train mF1 1.0000, val mF1 0.6788
Time: 0:07:05.359478
Epoch 33/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 33/60: train loss 0.0001, val loss 0.6125
Epoch 33/60: train mF1 1.0000, val mF1 0.6790
Time: 0:07:03.563530
Epoch 34/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 34/60: train loss 0.0001, val loss 0.6142
Epoch 34/60: train mF1 1.0000, val mF1 0.6785
Time: 0:06:57.138654
Epoch 35/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 35/60: train loss 0.0001, val loss 0.6165
Epoch 35/60: train mF1 1.0000, val mF1 0.6789
Time: 0:07:01.124788
Epoch 36/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 36/60: train loss 0.0001, val loss 0.6182
Epoch 36/60: train mF1 1.0000, val mF1 0.6783
Time: 0:07:01.927890
Epoch 37/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 37/60: train loss 0.0001, val loss 0.6190
Epoch 37/60: train mF1 1.0000, val mF1 0.6785
Time: 0:06:59.692834
Epoch 38/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 38/60: train loss 0.0001, val loss 0.6216
Epoch 38/60: train mF1 1.0000, val mF1 0.6786
Time: 0:06:59.993695
Epoch 39/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 39/60: train loss 0.0001, val loss 0.6227
Epoch 39/60: train mF1 1.0000, val mF1 0.6784
Time: 0:07:00.089553
Epoch 40/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 40/60: train loss 0.0001, val loss 0.6245
Epoch 40/60: train mF1 1.0000, val mF1 0.6785
Time: 0:07:00.962390
Epoch 41/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 41/60: train loss 0.0001, val loss 0.6260
Epoch 41/60: train mF1 1.0000, val mF1 0.6777
Time: 0:07:00.696311
Epoch 42/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 42/60: train loss 0.0001, val loss 0.6272
Epoch 42/60: train mF1 1.0000, val mF1 0.6779
Time: 0:06:59.087705
Epoch 43/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 43/60: train loss 0.0000, val loss 0.6296
Epoch 43/60: train mF1 1.0000, val mF1 0.6774
Time: 0:07:07.521167
Epoch 44/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 44/60: train loss 0.0000, val loss 0.6309
Epoch 44/60: train mF1 1.0000, val mF1 0.6775
Time: 0:06:58.432908
Epoch 45/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 45/60: train loss 0.0000, val loss 0.6322
Epoch 45/60: train mF1 1.0000, val mF1 0.6784
Time: 0:06:56.489990
Epoch 46/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 46/60: train loss 0.0000, val loss 0.6342
Epoch 46/60: train mF1 1.0000, val mF1 0.6777
Time: 0:06:56.014620
Epoch 47/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 47/60: train loss 0.0000, val loss 0.6353
Epoch 47/60: train mF1 1.0000, val mF1 0.6781
Time: 0:06:53.439958
Epoch 48/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 48/60: train loss 0.0000, val loss 0.6371
Epoch 48/60: train mF1 1.0000, val mF1 0.6779
Time: 0:06:58.786383
Epoch 49/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 49/60: train loss 0.0000, val loss 0.6381
Epoch 49/60: train mF1 1.0000, val mF1 0.6778
Time: 0:07:00.226471
Epoch 50/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 50/60: train loss 0.0000, val loss 0.6394
Epoch 50/60: train mF1 1.0000, val mF1 0.6778
Time: 0:06:57.258940
Epoch 51/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 51/60: train loss 0.0000, val loss 0.6409
Epoch 51/60: train mF1 1.0000, val mF1 0.6782
Time: 0:07:13.603139
Epoch 52/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 52/60: train loss 0.0000, val loss 0.6424
Epoch 52/60: train mF1 1.0000, val mF1 0.6781
Time: 0:07:03.621228
Epoch 53/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 53/60: train loss 0.0000, val loss 0.6431
Epoch 53/60: train mF1 1.0000, val mF1 0.6774
Time: 0:07:12.650485
Epoch 54/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 54/60: train loss 0.0000, val loss 0.6450
Epoch 54/60: train mF1 1.0000, val mF1 0.6774
Time: 0:06:50.741130
Epoch 55/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 55/60: train loss 0.0000, val loss 0.6470
Epoch 55/60: train mF1 1.0000, val mF1 0.6772
Time: 0:06:51.211300
Epoch 56/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 56/60: train loss 0.0000, val loss 0.6473
Epoch 56/60: train mF1 1.0000, val mF1 0.6773
Time: 0:06:52.569858
Epoch 57/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 57/60: train loss 0.0000, val loss 0.6493
Epoch 57/60: train mF1 1.0000, val mF1 0.6772
Time: 0:06:49.706539
Epoch 58/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 58/60: train loss 0.0000, val loss 0.6496
Epoch 58/60: train mF1 1.0000, val mF1 0.6778
Time: 0:06:49.787512
Epoch 59/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 59/60: train loss 0.0000, val loss 0.6521
Epoch 59/60: train mF1 1.0000, val mF1 0.6776
Time: 0:06:54.104255
Epoch 60/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 60/60: train loss 0.0000, val loss 0.6533
Epoch 60/60: train mF1 1.0000, val mF1 0.6772
/home/bertille/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Time: 0:06:55.767094
Testing
Batch: 0  over  10
Test F1 by class: [0.47068832 0.58364845 0.76909279 0.74672144 0.65769934 0.51104913
 0.37069323]
Test mF1: 0.5870846737915042
Plot saved at: ../../results/resnet18_64_l1/random_shuffling/all/resnet18_multi_label_64_random_60epochs_bs4096_pre_trained/metrics_test/test_preds.png
Reassembling the patches...
Reassembling the patches...
Reassembling the patches...
