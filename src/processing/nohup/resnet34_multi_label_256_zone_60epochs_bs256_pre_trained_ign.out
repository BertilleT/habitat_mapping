----------------------- UNet -----------------------
Patch size: 256
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.6, 0.2]
Stratified: random
Year: all
Patches: all
Batch size: 256
Normalisation: channel_by_channel
No data augmentation
The seed to shuffle the data is  1
The data are from  all  year
Image: min: 0.0, max: 1.0
Mask unique values: [0. 1.]
Train: 6228 images, Val: 2076 images, Test: 2359 images
Train: 58.41%, Val: 19.47%, Test: 22.12%
Creating model...
Model settings:
Pretrained: IGN
Classes: 7
The model is:  Resnet34
Using BCEWithDigits criterion
Creating optimizer...
Training settings:
Learning rate: 0.001
Criterion: BCEWithDigits
Optimizer: Adam
Training...
Epoch 1/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 1/60: train loss 0.4703, val loss 0.5089
Epoch 1/60: train mF1 0.5021, val mF1 0.5515
Time: 0:01:13.632581
Epoch 2/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 2/60: train loss 0.3814, val loss 0.4261
Epoch 2/60: train mF1 0.6213, val mF1 0.5527
Time: 0:01:11.897822
Epoch 3/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 3/60: train loss 0.3501, val loss 0.3990
Epoch 3/60: train mF1 0.6799, val mF1 0.6341
Time: 0:01:12.626387
Epoch 4/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 4/60: train loss 0.3218, val loss 0.4152
Epoch 4/60: train mF1 0.7117, val mF1 0.6032
Time: 0:01:12.978708
Epoch 5/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 5/60: train loss 0.2947, val loss 0.6152
Epoch 5/60: train mF1 0.7411, val mF1 0.4965
Time: 0:01:12.976650
Epoch 6/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 6/60: train loss 0.2751, val loss 0.4921
Epoch 6/60: train mF1 0.7611, val mF1 0.6009
Time: 0:01:13.691201
Epoch 7/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 7/60: train loss 0.2487, val loss 0.4341
Epoch 7/60: train mF1 0.7900, val mF1 0.6418
Time: 0:01:13.403629
Epoch 8/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 8/60: train loss 0.2356, val loss 0.4585
Epoch 8/60: train mF1 0.7989, val mF1 0.6462
Time: 0:01:13.764811
Epoch 9/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 9/60: train loss 0.1984, val loss 0.5846
Epoch 9/60: train mF1 0.8369, val mF1 0.5788
Time: 0:01:12.807390
Epoch 10/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 10/60: train loss 0.1713, val loss 0.7629
Epoch 10/60: train mF1 0.8644, val mF1 0.4679
Time: 0:01:12.086591
Epoch 11/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 11/60: train loss 0.1440, val loss 0.6855
Epoch 11/60: train mF1 0.8885, val mF1 0.6218
Time: 0:01:11.499723
Epoch 12/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 12/60: train loss 0.1116, val loss 0.5457
Epoch 12/60: train mF1 0.9162, val mF1 0.6861
Time: 0:01:11.598730
Epoch 13/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 13/60: train loss 0.0969, val loss 0.5951
Epoch 13/60: train mF1 0.9277, val mF1 0.6442
Time: 0:01:11.696629
Epoch 14/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 14/60: train loss 0.0813, val loss 0.7300
Epoch 14/60: train mF1 0.9412, val mF1 0.6598
Time: 0:01:10.918785
Epoch 15/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 15/60: train loss 0.0674, val loss 0.7677
Epoch 15/60: train mF1 0.9496, val mF1 0.6733
Time: 0:01:10.862297
Epoch 16/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 16/60: train loss 0.0492, val loss 0.5570
Epoch 16/60: train mF1 0.9677, val mF1 0.7051
Time: 0:01:11.221598
Epoch 17/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 17/60: train loss 0.0330, val loss 0.5872
Epoch 17/60: train mF1 0.9795, val mF1 0.7285
Time: 0:01:11.438709
Epoch 18/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 18/60: train loss 0.0264, val loss 0.6350
Epoch 18/60: train mF1 0.9837, val mF1 0.7067
Time: 0:01:11.056389
Epoch 19/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 19/60: train loss 0.0208, val loss 0.5677
Epoch 19/60: train mF1 0.9881, val mF1 0.7192
Time: 0:01:11.430089
Epoch 20/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 20/60: train loss 0.0308, val loss 0.6598
Epoch 20/60: train mF1 0.9815, val mF1 0.6796
Time: 0:01:11.591375
Epoch 21/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 21/60: train loss 0.0319, val loss 0.7030
Epoch 21/60: train mF1 0.9801, val mF1 0.6358
Time: 0:01:11.692747
Epoch 22/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 22/60: train loss 0.0307, val loss 0.6196
Epoch 22/60: train mF1 0.9792, val mF1 0.6950
Time: 0:01:11.644929
Epoch 23/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 23/60: train loss 0.0250, val loss 0.8296
Epoch 23/60: train mF1 0.9832, val mF1 0.6821
Time: 0:01:11.534199
Epoch 24/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 24/60: train loss 0.0180, val loss 0.7019
Epoch 24/60: train mF1 0.9881, val mF1 0.6997
Time: 0:01:11.792820
Epoch 25/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 25/60: train loss 0.0142, val loss 0.6817
Epoch 25/60: train mF1 0.9932, val mF1 0.7140
Time: 0:01:11.513724
Epoch 26/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 26/60: train loss 0.0178, val loss 0.7435
Epoch 26/60: train mF1 0.9899, val mF1 0.6938
Time: 0:01:10.836117
Epoch 27/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 27/60: train loss 0.0207, val loss 0.7686
Epoch 27/60: train mF1 0.9872, val mF1 0.6530
Time: 0:01:09.817886
Epoch 28/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 28/60: train loss 0.0189, val loss 0.8748
Epoch 28/60: train mF1 0.9882, val mF1 0.7149
Time: 0:01:11.795156
Epoch 29/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 29/60: train loss 0.0177, val loss 0.8685
Epoch 29/60: train mF1 0.9896, val mF1 0.6680
Time: 0:01:11.066204
Epoch 30/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 30/60: train loss 0.0137, val loss 0.7847
Epoch 30/60: train mF1 0.9917, val mF1 0.6695
Time: 0:01:11.263130
Epoch 31/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 31/60: train loss 0.0121, val loss 0.7464
Epoch 31/60: train mF1 0.9922, val mF1 0.7071
Time: 0:01:12.403945
Epoch 32/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 32/60: train loss 0.0139, val loss 0.8114
Epoch 32/60: train mF1 0.9924, val mF1 0.6842
Time: 0:01:11.334303
Epoch 33/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 33/60: train loss 0.0137, val loss 0.7334
Epoch 33/60: train mF1 0.9921, val mF1 0.7219
Time: 0:01:12.297192
Epoch 34/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 34/60: train loss 0.0157, val loss 0.8953
Epoch 34/60: train mF1 0.9908, val mF1 0.7032
Time: 0:01:12.265189
Epoch 35/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 35/60: train loss 0.0136, val loss 0.7220
Epoch 35/60: train mF1 0.9920, val mF1 0.7169
Time: 0:01:10.438127
Epoch 36/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 36/60: train loss 0.0103, val loss 0.7981
Epoch 36/60: train mF1 0.9934, val mF1 0.7127
Time: 0:01:10.572372
Epoch 37/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 37/60: train loss 0.0087, val loss 0.7579
Epoch 37/60: train mF1 0.9949, val mF1 0.7096
Time: 0:01:11.482742
Epoch 38/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 38/60: train loss 0.0075, val loss 0.7379
Epoch 38/60: train mF1 0.9951, val mF1 0.7225
Time: 0:01:11.363523
Epoch 39/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 39/60: train loss 0.0056, val loss 0.7217
Epoch 39/60: train mF1 0.9963, val mF1 0.7148
Time: 0:01:10.906417
Epoch 40/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 40/60: train loss 0.0040, val loss 0.7791
Epoch 40/60: train mF1 0.9979, val mF1 0.7171
Time: 0:01:11.868662
Epoch 41/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 41/60: train loss 0.0033, val loss 0.7482
Epoch 41/60: train mF1 0.9980, val mF1 0.7131
Time: 0:01:12.518133
Epoch 42/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 42/60: train loss 0.0032, val loss 0.7091
Epoch 42/60: train mF1 0.9987, val mF1 0.7274
Time: 0:01:11.257238
Epoch 43/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 43/60: train loss 0.0020, val loss 0.7423
Epoch 43/60: train mF1 0.9988, val mF1 0.7340
Time: 0:01:11.248527
Epoch 44/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 44/60: train loss 0.0015, val loss 0.7060
Epoch 44/60: train mF1 0.9996, val mF1 0.7339
Time: 0:01:11.979043
Epoch 45/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 45/60: train loss 0.0020, val loss 0.7467
Epoch 45/60: train mF1 0.9994, val mF1 0.7473
Time: 0:01:11.421791
Epoch 46/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 46/60: train loss 0.0031, val loss 0.7800
Epoch 46/60: train mF1 0.9983, val mF1 0.6996
Time: 0:01:11.246665
Epoch 47/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 47/60: train loss 0.0026, val loss 0.8910
Epoch 47/60: train mF1 0.9989, val mF1 0.7032
Time: 0:01:11.351167
Epoch 48/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 48/60: train loss 0.0038, val loss 0.7734
Epoch 48/60: train mF1 0.9986, val mF1 0.7182
Time: 0:01:11.319854
Epoch 49/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 49/60: train loss 0.0025, val loss 0.7631
Epoch 49/60: train mF1 0.9990, val mF1 0.7273
Time: 0:01:11.273910
Epoch 50/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 50/60: train loss 0.0129, val loss 1.0369
Epoch 50/60: train mF1 0.9935, val mF1 0.6797
Time: 0:01:11.395404
Epoch 51/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 51/60: train loss 0.0172, val loss 0.9646
Epoch 51/60: train mF1 0.9893, val mF1 0.6746
Time: 0:01:14.355109
Epoch 52/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 52/60: train loss 0.0320, val loss 1.1577
Epoch 52/60: train mF1 0.9792, val mF1 0.6289
Time: 0:01:12.364089
Epoch 53/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 53/60: train loss 0.0696, val loss 1.2158
Epoch 53/60: train mF1 0.9560, val mF1 0.6155
Time: 0:01:10.869433
Epoch 54/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 54/60: train loss 0.0826, val loss 1.4606
Epoch 54/60: train mF1 0.9411, val mF1 0.5028
Time: 0:01:10.825217
Epoch 55/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 55/60: train loss 0.0442, val loss 0.8494
Epoch 55/60: train mF1 0.9707, val mF1 0.6527
Time: 0:01:10.936616
Epoch 56/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 56/60: train loss 0.0205, val loss 0.7025
Epoch 56/60: train mF1 0.9889, val mF1 0.6963
Time: 0:01:10.813861
Epoch 57/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 57/60: train loss 0.0081, val loss 0.6104
Epoch 57/60: train mF1 0.9960, val mF1 0.7286
Time: 0:01:11.850237
Epoch 58/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 58/60: train loss 0.0034, val loss 0.6525
Epoch 58/60: train mF1 0.9990, val mF1 0.7278
Time: 0:01:10.958419
Epoch 59/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 59/60: train loss 0.0023, val loss 0.6350
Epoch 59/60: train mF1 0.9993, val mF1 0.7295
Time: 0:01:10.702414
Epoch 60/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 60/60: train loss 0.0011, val loss 0.6342
Epoch 60/60: train mF1 0.9997, val mF1 0.7273
/home/bertille/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/bertille/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Time: 0:01:11.294109
Testing
Batch: 0  over  10
Test F1 by class: [0.6407767  0.47526673 0.70477189 0.68982036 0.71230503 0.39583333
 0.76794258]
Test mF1: 0.6266738036752842
Plot saved at: ../../results/resnet34_256_l1/random_shuffling/all/resnet34_multi_label_256_zone_60epochs_bs256_pre_trained_ign/metrics_test/test_preds.png
Reassembling the patches...
f1_by_class:  [0. 0. 0. 0. 0. 0.]
post_f1_by_class [0. 0. 0. 0. 0.]
Reassembling the patches...
Reassembling the patches...
f1_by_class:  [0. 1. 0.]
post_f1_by_class [0. 1. 0.]
Reassembling the patches...
Reassembling the patches...
f1_by_class:  [0.         0.         0.42105263 0.         0.        ]
post_f1_by_class [0.        0.        0.7826087 0.        0.       ]
Reassembling the patches...
