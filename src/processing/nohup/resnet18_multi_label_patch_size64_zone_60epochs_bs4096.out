INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations
----------------------- UNet -----------------------
Patch size: 64
Classification level: 1
Using device: cuda
Loading data...
Data loading settings:
Splitting data: [0.68, 0.2]
Stratified: zone
Year: all
Patches: all
Batch size: 4096
Normalisation: channel_by_channel
No data augmentation
The seed to shuffle the data is  1
The data are from  all  year
Nbumber of unique zones: 108
Train, val and test zones saved in csv file at: ../../results/resnet18_64_l1/stratified_shuffling_by_zone/seed1/img_ids_by_set.csv
Image: min: 0.0, max: 1.0
Mask unique values: [0. 1.]
Train: 102118 images, Val: 36030 images, Test: 32320 images
Train: 59.90%, Val: 21.14%, Test: 18.96%
Creating model...
Model settings:
Pretrained: False
Classes: 7
The model is Resnet18
Using BCEWithDigits criterion
Creating optimizer...
Training settings:
Learning rate: 0.001
Criterion: BCEWithDigits
Optimizer: Adam
Training...
Epoch 1/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 1/60: train loss 0.4249, val loss 0.7954
Epoch 1/60: train mF1 0.3230, val mF1 0.0304
Time: 0:07:26.432311
Epoch 2/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 2/60: train loss 0.3465, val loss 0.5224
Epoch 2/60: train mF1 0.4479, val mF1 0.2521
Time: 0:07:07.800032
Epoch 3/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 3/60: train loss 0.3217, val loss 0.4381
Epoch 3/60: train mF1 0.5193, val mF1 0.2999
Time: 0:07:07.902671
Epoch 4/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 4/60: train loss 0.3016, val loss 0.4870
Epoch 4/60: train mF1 0.5623, val mF1 0.2635
Time: 0:07:07.877423
Epoch 5/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 5/60: train loss 0.2870, val loss 0.4416
Epoch 5/60: train mF1 0.5894, val mF1 0.2668
Time: 0:07:06.715543
Epoch 6/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 6/60: train loss 0.2730, val loss 0.4530
Epoch 6/60: train mF1 0.6155, val mF1 0.3054
Time: 0:07:07.798404
Epoch 7/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 7/60: train loss 0.2544, val loss 0.6286
Epoch 7/60: train mF1 0.6439, val mF1 0.2906
Time: 0:07:07.578428
Epoch 8/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 8/60: train loss 0.2318, val loss 0.5323
Epoch 8/60: train mF1 0.6867, val mF1 0.3302
Time: 0:07:07.194890
Epoch 9/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 9/60: train loss 0.2064, val loss 0.8243
Epoch 9/60: train mF1 0.7265, val mF1 0.3044
Time: 0:07:29.154736
Epoch 10/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 10/60: train loss 0.1718, val loss 0.7357
Epoch 10/60: train mF1 0.7810, val mF1 0.2596
Time: 0:07:29.473371
Epoch 11/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 11/60: train loss 0.1426, val loss 0.8090
Epoch 11/60: train mF1 0.8249, val mF1 0.2912
Time: 0:07:00.402482
Epoch 12/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 12/60: train loss 0.1123, val loss 0.7997
Epoch 12/60: train mF1 0.8665, val mF1 0.3083
Time: 0:06:59.111002
Epoch 13/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 13/60: train loss 0.0893, val loss 0.9026
Epoch 13/60: train mF1 0.8964, val mF1 0.3230
Time: 0:06:58.458984
Epoch 14/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 14/60: train loss 0.0689, val loss 0.9385
Epoch 14/60: train mF1 0.9237, val mF1 0.3108
Time: 0:07:06.284660
Epoch 15/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 15/60: train loss 0.0526, val loss 0.9870
Epoch 15/60: train mF1 0.9436, val mF1 0.3154
Time: 0:07:05.911593
Epoch 16/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 16/60: train loss 0.0434, val loss 1.0552
Epoch 16/60: train mF1 0.9548, val mF1 0.3138
Time: 0:07:05.737011
Epoch 17/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 17/60: train loss 0.0374, val loss 1.0803
Epoch 17/60: train mF1 0.9605, val mF1 0.3209
Time: 0:07:06.653017
Epoch 18/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 18/60: train loss 0.0314, val loss 1.0560
Epoch 18/60: train mF1 0.9669, val mF1 0.3321
Time: 0:07:06.935775
Epoch 19/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 19/60: train loss 0.0263, val loss 1.1506
Epoch 19/60: train mF1 0.9734, val mF1 0.3041
Time: 0:07:06.369915
Epoch 20/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 20/60: train loss 0.0238, val loss 1.1810
Epoch 20/60: train mF1 0.9762, val mF1 0.2859
Time: 0:07:04.663503
Epoch 21/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 21/60: train loss 0.0231, val loss 1.2244
Epoch 21/60: train mF1 0.9769, val mF1 0.3201
Time: 0:07:05.220575
Epoch 22/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 22/60: train loss 0.0198, val loss 1.3011
Epoch 22/60: train mF1 0.9811, val mF1 0.3063
Time: 0:07:05.257941
Epoch 23/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 23/60: train loss 0.0180, val loss 1.3045
Epoch 23/60: train mF1 0.9826, val mF1 0.2871
Time: 0:07:06.040910
Epoch 24/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 24/60: train loss 0.0168, val loss 1.3063
Epoch 24/60: train mF1 0.9835, val mF1 0.3048
Time: 0:07:05.406135
Epoch 25/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 25/60: train loss 0.0162, val loss 1.2762
Epoch 25/60: train mF1 0.9840, val mF1 0.3284
Time: 0:07:05.786591
Epoch 26/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 26/60: train loss 0.0168, val loss 1.3592
Epoch 26/60: train mF1 0.9836, val mF1 0.3117
Time: 0:07:05.204897
Epoch 27/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 27/60: train loss 0.0167, val loss 1.3228
Epoch 27/60: train mF1 0.9836, val mF1 0.2965
Time: 0:07:05.365594
Epoch 28/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 28/60: train loss 0.0154, val loss 1.2357
Epoch 28/60: train mF1 0.9854, val mF1 0.3198
Time: 0:07:05.996677
Epoch 29/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 29/60: train loss 0.0137, val loss 1.3835
Epoch 29/60: train mF1 0.9863, val mF1 0.3069
Time: 0:07:05.977131
Epoch 30/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 30/60: train loss 0.0124, val loss 1.3131
Epoch 30/60: train mF1 0.9883, val mF1 0.3337
Time: 0:07:06.470774
Epoch 31/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 31/60: train loss 0.0109, val loss 1.4117
Epoch 31/60: train mF1 0.9895, val mF1 0.3094
Time: 0:07:05.376209
Epoch 32/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 32/60: train loss 0.0116, val loss 1.4282
Epoch 32/60: train mF1 0.9887, val mF1 0.3288
Time: 0:07:06.058324
Epoch 33/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 33/60: train loss 0.0128, val loss 1.4920
Epoch 33/60: train mF1 0.9880, val mF1 0.3033
Time: 0:07:05.781769
Epoch 34/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 34/60: train loss 0.0126, val loss 1.3545
Epoch 34/60: train mF1 0.9874, val mF1 0.3362
Time: 0:07:06.114720
Epoch 35/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 35/60: train loss 0.0123, val loss 1.4374
Epoch 35/60: train mF1 0.9883, val mF1 0.3074
Time: 0:07:06.179662
Epoch 36/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 36/60: train loss 0.0143, val loss 1.2514
Epoch 36/60: train mF1 0.9862, val mF1 0.3215
Time: 0:07:06.785181
Epoch 37/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 37/60: train loss 0.0147, val loss 1.5940
Epoch 37/60: train mF1 0.9855, val mF1 0.2814
Time: 0:07:05.427215
Epoch 38/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 38/60: train loss 0.0126, val loss 1.4618
Epoch 38/60: train mF1 0.9878, val mF1 0.2921
Time: 0:07:05.749352
Epoch 39/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 39/60: train loss 0.0111, val loss 1.3829
Epoch 39/60: train mF1 0.9895, val mF1 0.3161
Time: 0:07:05.233346
Epoch 40/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 40/60: train loss 0.0094, val loss 1.6111
Epoch 40/60: train mF1 0.9915, val mF1 0.2795
Time: 0:07:05.287379
Epoch 41/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 41/60: train loss 0.0080, val loss 1.4123
Epoch 41/60: train mF1 0.9926, val mF1 0.3069
Time: 0:07:05.143618
Epoch 42/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 42/60: train loss 0.0070, val loss 1.8031
Epoch 42/60: train mF1 0.9935, val mF1 0.2625
Time: 0:07:05.510262
Epoch 43/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 43/60: train loss 0.0067, val loss 1.4830
Epoch 43/60: train mF1 0.9937, val mF1 0.3243
Time: 0:07:05.464676
Epoch 44/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 44/60: train loss 0.0067, val loss 1.8384
Epoch 44/60: train mF1 0.9938, val mF1 0.2913
Time: 0:07:05.797068
Epoch 45/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 45/60: train loss 0.0081, val loss 1.5497
Epoch 45/60: train mF1 0.9919, val mF1 0.3244
Time: 0:07:05.304855
Epoch 46/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 46/60: train loss 0.0090, val loss 1.5197
Epoch 46/60: train mF1 0.9914, val mF1 0.3065
Time: 0:07:04.659823
Epoch 47/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 47/60: train loss 0.0110, val loss 1.5550
Epoch 47/60: train mF1 0.9892, val mF1 0.2817
Time: 0:07:05.106665
Epoch 48/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 48/60: train loss 0.0120, val loss 1.4207
Epoch 48/60: train mF1 0.9881, val mF1 0.3178
Time: 0:07:04.743126
Epoch 49/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 49/60: train loss 0.0122, val loss 1.3282
Epoch 49/60: train mF1 0.9881, val mF1 0.3011
Time: 0:07:05.307373
Epoch 50/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 50/60: train loss 0.0115, val loss 1.3632
Epoch 50/60: train mF1 0.9889, val mF1 0.3147
Time: 0:07:04.802681
Epoch 51/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 51/60: train loss 0.0110, val loss 1.4038
Epoch 51/60: train mF1 0.9896, val mF1 0.3246
Time: 0:07:05.772338
Epoch 52/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 52/60: train loss 0.0090, val loss 1.3350
Epoch 52/60: train mF1 0.9913, val mF1 0.3289
Time: 0:07:04.860142
Epoch 53/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 53/60: train loss 0.0084, val loss 1.5025
Epoch 53/60: train mF1 0.9920, val mF1 0.3380
Time: 0:07:05.223970
Epoch 54/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 54/60: train loss 0.0082, val loss 1.4230
Epoch 54/60: train mF1 0.9926, val mF1 0.3171
Time: 0:07:05.067076
Epoch 55/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 55/60: train loss 0.0079, val loss 1.4455
Epoch 55/60: train mF1 0.9925, val mF1 0.3037
Time: 0:07:05.806434
Epoch 56/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 56/60: train loss 0.0067, val loss 1.3581
Epoch 56/60: train mF1 0.9939, val mF1 0.3223
Time: 0:07:05.100327
Epoch 57/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 57/60: train loss 0.0079, val loss 1.4953
Epoch 57/60: train mF1 0.9926, val mF1 0.2890
Time: 0:07:09.232732
Epoch 58/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 58/60: train loss 0.0077, val loss 1.4238
Epoch 58/60: train mF1 0.9926, val mF1 0.3394
Time: 0:07:02.992835
Epoch 59/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 59/60: train loss 0.0085, val loss 1.4577
Epoch 59/60: train mF1 0.9919, val mF1 0.3200
Time: 0:07:03.318591
Epoch 60/60
Training
Batch: 0  over  25
Validation
Batch: 0  over  9
Epoch 60/60: train loss 0.0086, val loss 1.4996
Epoch 60/60: train mF1 0.9918, val mF1 0.3112
/home/bertille/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/home/bertille/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Time: 0:07:02.552560
Testing
Batch: 0  over  8
Test F1 by class: [0.38640156 0.23697095 0.65063402 0.20802828 0.5593101  0.09412597
 0.19433818]
Test mF1: 0.3328298650571852
Plot saved at: ../../results/resnet18_64_l1/stratified_shuffling_by_zone/all/resnet18_multi_label_64_zone_60epochs_bs4096/metrics_test/test_preds.png
Reassembling the patches...
Reassembling the patches...
Reassembling the patches...
